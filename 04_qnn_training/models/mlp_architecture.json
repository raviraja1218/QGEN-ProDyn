{
  "layers": [
    32,
    64,
    32,
    1
  ],
  "activation": "relu",
  "optimizer": "Adam",
  "lr": 0.001,
  "loss": "MSE",
  "params": 760
}